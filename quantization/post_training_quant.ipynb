{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Y8E0lw5eYWm"
   },
   "source": [
    "# Post Training Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CIGrZZPTZVeO"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/tutorials/post_training_quant.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tutorials/post_training_quant.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTC1rDAuei_1"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[TensorFlow Lite](https://www.tensorflow.org/lite/) now supports\n",
    "converting weights to 8 bit precision as part of model conversion from\n",
    "tensorflow graphdefs to TFLite's flat buffer format. Weight quantization\n",
    "achieves a 4x reduction in the model size. In addition, `TFLite supports on the\n",
    "fly quantization and dequantization of activations to allow for`:\n",
    "\n",
    "1.  `Using quantized kernels for faster implementation when available.`\n",
    "\n",
    "2.  `Mixing of floating-point kernels with quantized kernels for different parts\n",
    "    of the graph.`\n",
    "\n",
    "Note that `the activations are always stored in floating point. For ops that\n",
    "support quantized kernels, the activations are quantized to 8 bits of precision\n",
    "dynamically prior to processing and are de-quantized to float precision after\n",
    "processing. Depending on the model being converted, this can give a speedup over\n",
    "pure floating point computation.`\n",
    "\n",
    "In contrast to\n",
    "[quantization aware training](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/quantize)\n",
    ", the weights are quantized post training and the activations are quantized dynamically \n",
    "at inference in this method.\n",
    "Therefore, the model weights are not retrained to compensate for quantization\n",
    "induced errors. It is important to check the accuracy of the quantized model to\n",
    "ensure that the degradation is acceptable.\n",
    "\n",
    "`In this tutorial, we train an MNIST model from scratch, check its accuracy in\n",
    "tensorflow and then convert the saved model into a Tensorflow Lite flatbuffer\n",
    "with weight quantization`. We finally check the\n",
    "accuracy of the converted model and compare it to the original saved model. We\n",
    "run the training script mnist.py from\n",
    "[Tensorflow official mnist tutorial](https://github.com/tensorflow/models/tree/master/official/mnist).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XsEP17Zelz9"
   },
   "source": [
    "## Building an MNIST model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDqqUIZjZjac"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyqAw1M9lyab"
   },
   "outputs": [],
   "source": [
    "# Note: Nightly Builds are now CUDA 10 as of 16-DEC-2018\n",
    "# But currently, I use CUDA 8. So I use \"pip install tf-nightly-gpu==1.13.0.dev20181210\"\n",
    "# https://github.com/tensorflow/tensorflow/issues/22706\n",
    "# ! pip uninstall -y tensorflow\n",
    "# ! pip install -U tf-nightly-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsN6s5L1ieNl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "# 通過使用 tf.enable_eager_execution() 可以獲得實際值。在 eager_execution中，操作的輸出將是實際值而不是張量。\n",
    "# 使用 Eager Execution，你可以在沒有 session 的情況下運行你的代碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00U0taBoe-w7"
   },
   "outputs": [],
   "source": [
    "# 下載 TensorFlow 官方所提供的預設 model\n",
    "# ! git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XZPtSh-fUOc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models path: /home/ryanyao/work/my_ml_study/TensorFlow_Study_1112/quantization/models\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if sys.version_info.major >= 3:\n",
    "    import pathlib\n",
    "else:\n",
    "    import pathlib2 as pathlib\n",
    "\n",
    "# Add `models` to the python path.\n",
    "models_path = os.path.join(os.getcwd(), \"models\")\n",
    "sys.path.append(models_path)\n",
    "print(\"models path:\", models_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQ6Q0qqKZogR"
   },
   "source": [
    "### Train and export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMsw_6HujaqM"
   },
   "outputs": [],
   "source": [
    "saved_models_root = \"/tmp/mnist_saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWSAjQWagIHl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-19 19:12:43.357482: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-12-19 19:12:43.656666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2018-12-19 19:12:43.667056: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55991ace10d0 executing computations on platform CUDA. Devices:\n",
      "2018-12-19 19:12:43.667076: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1060 3GB, Compute Capability 6.1\n",
      "2018-12-19 19:12:43.808153: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3392130000 Hz\n",
      "2018-12-19 19:12:43.808332: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55991ad99ae0 executing computations on platform Host. Devices:\n",
      "2018-12-19 19:12:43.808354: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2018-12-19 19:12:43.808585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1431] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 2.94GiB freeMemory: 2.84GiB\n",
      "2018-12-19 19:12:43.808620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Adding visible gpu devices: 0\n",
      "2018-12-19 19:12:43.809619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-19 19:12:43.809643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-19 19:12:43.809655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-19 19:12:43.809834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1113] Created TensorFlow device (/device:GPU:0 with 2604 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "I1219 19:12:50.769276 140627962443584 run_config.py:532] Initializing RunConfig with distribution strategies.\n",
      "I1219 19:12:50.769457 140627962443584 estimator_training.py:166] Not using Distribute Coordinator.\n",
      "I1219 19:12:50.776410 140627962443584 estimator.py:201] Using config: {'_model_dir': '/tmp/mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x7fe61858add8>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe61858aeb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "W1219 19:12:50.891189 140627962443584 deprecation.py:317] From /home/ryanyao/work/my_ml_study/TensorFlow_Study_1112/quantization/models/official/mnist/dataset.py:100: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W1219 19:12:50.965167 140627962443584 deprecation.py:317] From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:205: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "W1219 19:12:50.965885 140627962443584 deprecation.py:317] From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:1401: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "I1219 19:12:50.997256 140627962443584 estimator.py:1111] Calling model_fn.\n",
      "W1219 19:12:51.085868 140627962443584 deprecation.py:500] From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1219 19:12:51.143463 140627962443584 deprecation.py:317] From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "I1219 19:12:51.455617 140627962443584 estimator.py:1113] Done calling model_fn.\n",
      "I1219 19:12:51.561392 140627962443584 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n",
      "I1219 19:12:51.734545 140627962443584 monitored_session.py:222] Graph was finalized.\n",
      "2018-12-19 19:12:51.734996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Adding visible gpu devices: 0\n",
      "2018-12-19 19:12:51.735040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-19 19:12:51.735049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-19 19:12:51.735056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-19 19:12:51.735188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1113] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2604 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "W1219 19:12:51.797447 140627962443584 deprecation.py:317] From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I1219 19:12:51.818226 140627962443584 saver.py:1270] Restoring parameters from /tmp/mnist_model/model.ckpt-1800\n",
      "W1219 19:12:52.508676 140627962443584 deprecation.py:317] From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "I1219 19:12:52.579859 140627962443584 session_manager.py:491] Running local_init_op.\n",
      "I1219 19:12:52.589773 140627962443584 session_manager.py:493] Done running local_init_op.\n",
      "I1219 19:12:52.794642 140627962443584 basic_session_run_hooks.py:594] Saving checkpoints for 1800 into /tmp/mnist_model/model.ckpt.\n",
      "W1219 19:12:53.020121 140627962443584 deprecation.py:317] From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_management.py:229: generate_checkpoint_state_proto (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than editing the Checkpoint proto manually.\n",
      "2018-12-19 19:12:53.665645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Adding visible gpu devices: 0\n",
      "2018-12-19 19:12:53.665701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-19 19:12:53.665713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-19 19:12:53.665722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-19 19:12:53.665851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1113] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2604 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2018-12-19 19:12:53.672250: I tensorflow/core/grappler/mutable_graph_view.cc:71] Update fanouts from 'RepeatDataset/_27' to 'BatchDatasetV2/_25'.\n",
      "I1219 19:12:53.692745 140627962443584 util.py:164] Initialize strategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-19 19:12:53.896360: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.9.0 locally\n",
      "I1219 19:13:07.367123 140627962443584 basic_session_run_hooks.py:249] cross_entropy = 0.061259326, learning_rate = 1e-04, train_accuracy = 0.97\n",
      "I1219 19:13:07.367995 140627962443584 basic_session_run_hooks.py:249] loss = 0.061259326, step = 1800\n",
      "I1219 19:13:08.168468 140627962443584 basic_session_run_hooks.py:680] global_step/sec: 124.625\n",
      "I1219 19:13:08.168969 140627962443584 basic_session_run_hooks.py:247] cross_entropy = 0.0578548, learning_rate = 1e-04, train_accuracy = 0.98 (0.802 sec)\n",
      "I1219 19:13:08.169080 140627962443584 basic_session_run_hooks.py:247] loss = 0.0578548, step = 1900 (0.801 sec)\n",
      "I1219 19:13:08.805134 140627962443584 basic_session_run_hooks.py:680] global_step/sec: 157.067\n",
      "I1219 19:13:08.805649 140627962443584 basic_session_run_hooks.py:247] cross_entropy = 0.04504158, learning_rate = 1e-04, train_accuracy = 0.98333335 (0.637 sec)\n",
      "I1219 19:13:08.805820 140627962443584 basic_session_run_hooks.py:247] loss = 0.04504158, step = 2000 (0.637 sec)\n",
      "I1219 19:13:09.442415 140627962443584 basic_session_run_hooks.py:680] global_step/sec: 156.916\n",
      "I1219 19:13:09.442932 140627962443584 basic_session_run_hooks.py:247] cross_entropy = 0.100686006, learning_rate = 1e-04, train_accuracy = 0.98 (0.637 sec)\n",
      "I1219 19:13:09.443043 140627962443584 basic_session_run_hooks.py:247] loss = 0.100686006, step = 2100 (0.637 sec)\n",
      "I1219 19:13:10.079360 140627962443584 basic_session_run_hooks.py:680] global_step/sec: 157\n",
      "I1219 19:13:10.079876 140627962443584 basic_session_run_hooks.py:247] cross_entropy = 0.026615247, learning_rate = 1e-04, train_accuracy = 0.982 (0.637 sec)\n",
      "I1219 19:13:10.079985 140627962443584 basic_session_run_hooks.py:247] loss = 0.026615247, step = 2200 (0.637 sec)\n",
      "I1219 19:13:10.714946 140627962443584 basic_session_run_hooks.py:680] global_step/sec: 157.335\n",
      "I1219 19:13:10.715445 140627962443584 basic_session_run_hooks.py:247] cross_entropy = 0.021283202, learning_rate = 1e-04, train_accuracy = 0.985 (0.636 sec)\n",
      "I1219 19:13:10.715556 140627962443584 basic_session_run_hooks.py:247] loss = 0.021283202, step = 2300 (0.636 sec)\n",
      "I1219 19:13:11.421732 140627962443584 basic_session_run_hooks.py:594] Saving checkpoints for 2400 into /tmp/mnist_model/model.ckpt.\n",
      "I1219 19:13:11.491572 140627962443584 util.py:168] Finalize strategy.\n",
      "I1219 19:13:11.548782 140627962443584 estimator.py:359] Loss for final step: 0.041760158.\n",
      "W1219 19:13:11.594070 140627962443584 deprecation.py:317] From models/official/mnist/mnist.py:202: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "I1219 19:13:11.606397 140627962443584 estimator.py:1111] Calling model_fn.\n",
      "I1219 19:13:11.714658 140627962443584 estimator.py:1113] Done calling model_fn.\n",
      "I1219 19:13:11.727740 140627962443584 evaluation.py:257] Starting evaluation at 2018-12-19-11:13:11\n",
      "I1219 19:13:11.784370 140627962443584 monitored_session.py:222] Graph was finalized.\n",
      "2018-12-19 19:13:11.784664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Adding visible gpu devices: 0\n",
      "2018-12-19 19:13:11.784705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-19 19:13:11.784714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-19 19:13:11.784721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-19 19:13:11.784833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1113] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2604 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "I1219 19:13:11.786017 140627962443584 saver.py:1270] Restoring parameters from /tmp/mnist_model/model.ckpt-2400\n",
      "I1219 19:13:11.834216 140627962443584 session_manager.py:491] Running local_init_op.\n",
      "I1219 19:13:11.859265 140627962443584 session_manager.py:493] Done running local_init_op.\n",
      "2018-12-19 19:13:11.917750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Adding visible gpu devices: 0\n",
      "2018-12-19 19:13:11.917801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-19 19:13:11.917811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-19 19:13:11.917819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-19 19:13:11.917928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1113] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2604 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "I1219 19:13:12.551930 140627962443584 evaluation.py:277] Finished evaluation at 2018-12-19-11:13:12\n",
      "I1219 19:13:12.552136 140627962443584 estimator.py:1979] Saving dict for global step 2400: accuracy = 0.9874, global_step = 2400, loss = 0.037608907\n",
      "I1219 19:13:12.589736 140627962443584 estimator.py:2039] Saving 'checkpoint_path' summary for global step 2400: /tmp/mnist_model/model.ckpt-2400\n",
      "\n",
      "Evaluation results:\n",
      "\t{'accuracy': 0.9874, 'loss': 0.037608907, 'global_step': 2400}\n",
      "\n",
      "I1219 19:13:12.604772 140627962443584 estimator.py:1111] Calling model_fn.\n",
      "I1219 19:13:12.691099 140627962443584 estimator.py:1113] Done calling model_fn.\n",
      "W1219 19:13:12.691283 140627962443584 deprecation.py:317] From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "I1219 19:13:12.691531 140627962443584 export.py:587] Signatures INCLUDED in export for Classify: None\n",
      "I1219 19:13:12.691603 140627962443584 export.py:587] Signatures INCLUDED in export for Regress: None\n",
      "I1219 19:13:12.691657 140627962443584 export.py:587] Signatures INCLUDED in export for Predict: ['classify', 'serving_default']\n",
      "I1219 19:13:12.691701 140627962443584 export.py:587] Signatures INCLUDED in export for Train: None\n",
      "I1219 19:13:12.691742 140627962443584 export.py:587] Signatures INCLUDED in export for Eval: None\n",
      "2018-12-19 19:13:12.691960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Adding visible gpu devices: 0\n",
      "2018-12-19 19:13:12.692015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-19 19:13:12.692024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-19 19:13:12.692031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-19 19:13:12.692137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1113] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2604 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "I1219 19:13:12.710230 140627962443584 saver.py:1270] Restoring parameters from /tmp/mnist_model/model.ckpt-2400\n",
      "I1219 19:13:12.730561 140627962443584 builder_impl.py:654] Assets added to graph.\n",
      "I1219 19:13:12.730702 140627962443584 builder_impl.py:449] No assets to write.\n",
      "I1219 19:13:12.773364 140627962443584 builder_impl.py:414] SavedModel written to: /tmp/mnist_saved_model/temp-b'1545217992'/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# The above path addition is not visible to subprocesses, add the path for the subprocess as well.\n",
    "# Note: channels_last is required here or the conversion may fail. \n",
    "!PYTHONPATH={models_path} python models/official/mnist/mnist.py --train_epochs=1 --export_dir {saved_models_root} --data_format=channels_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5NMaNZQCkW9X"
   },
   "source": [
    "For the example, we only trained the model for a single epoch, so it only trains to ~96% accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xl8_fzVAZwOh"
   },
   "source": [
    "### Convert to a TFLite model\n",
    "\n",
    "The `savedmodel` directory is named with a timestamp. Select the most recent one: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xp5oClaZkbtn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/mnist_saved_model/1545217992'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_dir = str(sorted(pathlib.Path(saved_models_root).glob(\"*\"))[-1])\n",
    "saved_model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AT8BgkKmljOy"
   },
   "source": [
    "Using the python `TFLiteConverter`, the saved model can be converted into a TFLite model.\n",
    "\n",
    "First load the model using the `TFLiteConverter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_i8B2nDZmAgQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/lite/python/convert_saved_model.py:61: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_saved_model/1545217992/variables/variables\n",
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', 'classify'}\n",
      "INFO:tensorflow:input tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: image\n",
      "INFO:tensorflow: tensor name: Placeholder:0, shape: (-1, 28, 28), type: DT_FLOAT\n",
      "INFO:tensorflow:output tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: probabilities\n",
      "INFO:tensorflow: tensor name: Softmax:0, shape: (-1, 10), type: DT_FLOAT\n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: classes\n",
      "INFO:tensorflow: tensor name: ArgMax:0, shape: (-1), type: DT_INT64\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_saved_model/1545217992/variables/variables\n",
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/lite/python/convert_saved_model.py:275: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2o2ZfF0aiCx"
   },
   "source": [
    "Write it out to a tflite file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vptWZq2xnclo"
   },
   "outputs": [],
   "source": [
    "tflite_models_dir = pathlib.Path(\"/tmp/mnist_tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ie9pQaQrn5ue"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13101280"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BONhYtYocQY"
   },
   "source": [
    "To quantize the model on export, set the `post_training_quantize` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8PUvLWDlmmz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3283208"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: If you don't have a recent tf-nightly installed, the\n",
    "# \"post_training_quantize\" line will have no effect.\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "converter.post_training_quantize = True\n",
    "tflite_quant_model = converter.convert()\n",
    "tflite_model_quant_file = tflite_models_dir/\"mnist_model_quant.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhMmUTl4sbkz"
   },
   "source": [
    "Note how the resulting file, with `post_training_quantize` set, is approximately `1/4` the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JExfcfLDscu4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16M\r\n",
      "-rw-rw-r-- 1 ryanyao ryanyao 3.2M Dec 19 19:13 mnist_model_quant.tflite\r\n",
      "-rw-rw-r-- 1 ryanyao ryanyao  13M Dec 19 19:13 mnist_model.tflite\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {tflite_models_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8lQHMp_asCq"
   },
   "source": [
    "## Run the TFLite models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5l6-ciItvX6"
   },
   "source": [
    "We can run the TensorFlow Lite model using the python TensorFlow Lite\n",
    "Interpreter. \n",
    "\n",
    "### load the test data\n",
    "\n",
    "First let's load the mnist test data to feed to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTIuU07NuKFL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-68502d728b13>:5: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Return: Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n",
    "images, labels = tf.to_float(mnist_test[0])/255.0, mnist_test[1]\n",
    "\n",
    "# Note: If you change the batch size, then use \n",
    "# `tf.lite.Interpreter.resize_tensor_input` to also change it for\n",
    "# the interpreter.\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images, labels)).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ap_jE7QRvhPf"
   },
   "source": [
    "### Load the model into an interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jn16Rc23zTss"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8Pztk1mvNVL"
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Afl6yGvWyqAr"
   },
   "outputs": [],
   "source": [
    "interpreter_quant.allocate_tensors()\n",
    "input_index = interpreter_quant.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_quant.get_output_details()[0][\"index\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2opUt_JTdyEu"
   },
   "source": [
    "### Test the model on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKslvo2kwWac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "for img, label in mnist_ds.take(1):\n",
    "  break\n",
    "\n",
    "interpreter.set_tensor(input_index, img)\n",
    "interpreter.invoke()\n",
    "predictions = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZClM2vo3_bm"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.imshow(img[0])\n",
    "template = \"True:{true}, predicted:{predict}\"\n",
    "_ = plt.title(template.format(true= str(label[0].numpy()),\n",
    "                              predict=str(predictions[0,0])))\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LwN7uIdCd8Gw"
   },
   "source": [
    "### Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05aeAuWjvjPx"
   },
   "outputs": [],
   "source": [
    "def eval_model(interpreter, mnist_ds):\n",
    "  total_seen = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for img, label in mnist_ds:\n",
    "    total_seen += 1\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    predictions = interpreter.get_tensor(output_index)\n",
    "    if predictions == label.numpy():\n",
    "      num_correct += 1\n",
    "\n",
    "    if total_seen % 500 == 0:\n",
    "        print(\"Accuracy after %i images: %f\" %\n",
    "              (total_seen, float(num_correct) / float(total_seen)))\n",
    "\n",
    "  return float(num_correct) / float(total_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqXBnDfJ7qxL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 500 images: 0.992000\n",
      "Accuracy after 1000 images: 0.985000\n",
      "Accuracy after 1500 images: 0.982000\n",
      "Accuracy after 2000 images: 0.982500\n",
      "Accuracy after 2500 images: 0.981200\n",
      "Accuracy after 3000 images: 0.982000\n",
      "Accuracy after 3500 images: 0.983143\n",
      "Accuracy after 4000 images: 0.983000\n",
      "Accuracy after 4500 images: 0.982667\n",
      "Accuracy after 5000 images: 0.982400\n",
      "Accuracy after 5500 images: 0.984000\n",
      "Accuracy after 6000 images: 0.984000\n",
      "Accuracy after 6500 images: 0.985231\n",
      "Accuracy after 7000 images: 0.985143\n",
      "Accuracy after 7500 images: 0.986000\n",
      "Accuracy after 8000 images: 0.986875\n",
      "Accuracy after 8500 images: 0.987294\n",
      "Accuracy after 9000 images: 0.988000\n",
      "Accuracy after 9500 images: 0.988421\n",
      "Accuracy after 10000 images: 0.987400\n",
      "0.9874\n",
      "21.2 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(eval_model(interpreter, mnist_ds))\n",
    "duration = time.time() - start_time\n",
    "print('%.1f sec' % (duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Km3cY9ry8ZlG"
   },
   "source": [
    "We can repeat the evaluation on the weight quantized model to obtain:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9cnwiPp6EGm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 500 images: 0.992000\n",
      "Accuracy after 1000 images: 0.985000\n",
      "Accuracy after 1500 images: 0.982000\n",
      "Accuracy after 2000 images: 0.982500\n",
      "Accuracy after 2500 images: 0.981200\n",
      "Accuracy after 3000 images: 0.982000\n",
      "Accuracy after 3500 images: 0.983143\n",
      "Accuracy after 4000 images: 0.983000\n",
      "Accuracy after 4500 images: 0.982667\n",
      "Accuracy after 5000 images: 0.982400\n",
      "Accuracy after 5500 images: 0.984000\n",
      "Accuracy after 6000 images: 0.984000\n",
      "Accuracy after 6500 images: 0.985231\n",
      "Accuracy after 7000 images: 0.985143\n",
      "Accuracy after 7500 images: 0.986000\n",
      "Accuracy after 8000 images: 0.986875\n",
      "Accuracy after 8500 images: 0.987294\n",
      "Accuracy after 9000 images: 0.988000\n",
      "Accuracy after 9500 images: 0.988421\n",
      "Accuracy after 10000 images: 0.987400\n",
      "0.9874\n",
      "53.8 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(eval_model(interpreter_quant, mnist_ds))\n",
    "duration = time.time() - start_time\n",
    "print('%.1f sec' % (duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7lfxkor8pgv"
   },
   "source": [
    "In this example, we have compressed model with no difference in the accuracy.  \n",
    "但目前在 time cost 的結果，quantized 後的反而較秏時 (unquantized: 22.6 sec, quantized: 53.9 sec)，可見以下討論  \n",
    "* [Slow quantized graph #2807](https://github.com/tensorflow/tensorflow/issues/2807)  \n",
    "  * Quantized ops currently only work on the CPU, because most GPUs don't support eight-bit matrix multiplications natively.  \n",
    "  * If I quantize the graph and run it on iOS (CPU), I too get about 3 times worse performance than running the unquantized version.\n",
    "  * The quantization is aimed at mobile performance, so most of the optimizations are for ARM not x86. We're hoping to get good quantization on Intel eventually, but we don't have anyone actively working on it yet.\n",
    "  * We are focusing our eight-bit efforts on TF Lite, so we aren't expecting TensorFlow's quantized performance to improve in cases where it's not currently fast. Close the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0o1FtmWeKZm"
   },
   "source": [
    "\n",
    "\n",
    "## Optimizing an existing model\n",
    "\n",
    "We now consider another example. Resnets with pre-activation layers (Resnet-v2) are widely used for vision applications.\n",
    "  Pre-trained frozen graph for resnet-v2-101 is available at the\n",
    "  [Tensorflow Lite model repository](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models.md).\n",
    "\n",
    "We can convert the frozen graph to a TFLite flatbuffer with quantization by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5p5VcNPjILQ"
   },
   "outputs": [],
   "source": [
    "archive_path = tf.keras.utils.get_file(\"resnet_v2_101.tgz\", \"https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/resnet_v2_101.tgz\", extract=True)\n",
    "archive_path = pathlib.Path(archive_path)\n",
    "archive_dir = str(archive_path.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-sxnXQuC4ThD"
   },
   "source": [
    "The `info.txt` file lists the input and output names. You can also find them using TensorBoard to visually inspect the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_Q_OMEJ4LIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet_v2_101\r\n",
      "Input: input\r\n",
      "Output: output\r\n"
     ]
    }
   ],
   "source": [
    "! cat {archive_dir}/resnet_v2_101_299_info.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujCAFhqm-C6H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44997240"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_def_file = pathlib.Path(archive_path).parent/\"resnet_v2_101_299_frozen.pb\"\n",
    "input_arrays = [\"input\"] \n",
    "output_arrays = [\"output\"]\n",
    "converter = tf.lite.TFLiteConverter.from_frozen_graph(\n",
    "  str(graph_def_file), input_arrays, output_arrays, input_shapes={\"input\":[1,299,299,3]})\n",
    "converter.post_training_quantize = True\n",
    "resnet_tflite_file = graph_def_file.parent/\"resnet_v2_101_quantized.tflite\"\n",
    "resnet_tflite_file.write_bytes(converter.convert())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhOjeg1x9Knp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ryanyao ryanyao 171M Sep  6 04:56 /home/ryanyao/.keras/datasets/resnet_v2_101_299.tflite\r\n",
      "-rw-rw-r-- 1 ryanyao ryanyao  43M Dec 19 19:15 /home/ryanyao/.keras/datasets/resnet_v2_101_quantized.tflite\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls -lh {archive_dir}/*.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqHLaqFMCjRZ"
   },
   "source": [
    "\n",
    "The model size reduces from 171 MB to 43 MB.\n",
    "The accuracy of this model on imagenet can be evaluated using the scripts provided for [TFLite accuracy measurement](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/accuracy/ilsvrc).\n",
    "\n",
    "The optimized model top-1 accuracy is 76.8, the same as the floating point model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "post-training-quant.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
