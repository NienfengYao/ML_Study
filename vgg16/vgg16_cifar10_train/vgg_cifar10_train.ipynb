{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic:\n",
    "* Implementing VGG16 in Tensorflow with CIFAR-10 dataset.\n",
    "  * 訓練的過程\n",
    "    * Batch size = 1200\n",
    "    * TRAINING_STEPS=6000\n",
    "    * 所以 training 時所用到的資料量為 1200*6000 張圖片\n",
    "  * 訓練出來的效果\n",
    "    * 此例的 accuracy 為 `Average Testing Accuracy = 0.80`.\n",
    "  * 以此例的 VGG16 模型(以VGG_Train來替代) 與之前 [vgg16_pretrained_predict.ipynb](vgg16/vgg16_pretrained_predict.ipynb)(在此用 VGG16_Pre 替代) 的比較\n",
    "    * 均有用到 dropout 機制\n",
    "    * VGG_Train 在每一個 hidden layer，都有做 batch normalization\n",
    "    * VGG16_Pre 在 training 前先將 values in image 減去 mean value, VGG16_Pre 則無。是否因為在每一層中均有做 batch normalization，所以不需這個步驟。\n",
    "    * Convolution 是一致的：\n",
    "      * kernel size = 3x3, stride = 1\n",
    "    * Pooling 並不一致：\n",
    "      * VGG16_Pre: 固定，kernel size = 2x2, stride = 2\n",
    "      * VGG16_Train: \n",
    "        * pool1: kernel size = 3x3, stride = 1\n",
    "        * others: kernel size = 3x3, stride = 2\n",
    "  * 在 training procedure 中的 accuracy 是由 train dataset 算出來的，不客觀。應該採用獨立於 training procedure 中的 dataset (ex: test dataset) 來做 accuracy 才是。\n",
    "    * 較正確的作法應該是將 train \n",
    "    * 但這應該不會影響到 training procedure 的正確率。因為 training procedure 中是用 loss 來修正權重的，而非 accuracy。\n",
    "* ToDo\n",
    "  * 用整個 test dataset，算出目前的 accuracy (Done)\n",
    "    * vgg_eval()\n",
    "  * 是否該將 CIFAR-10 的 dataset (Halt)。`應該不會影響 training procedure 的結果，因為是用 lost 來修正權重的。`\n",
    "    * 將 train dataset 分割成 90% train + 10% validate\n",
    "    * test dataset 則用在最後，評做整體 accuracy 之用\n",
    "    * 如此將 test dataset 隔離於 training procedure 之外，對於 accuracy 較為客觀\n",
    "  * 用 VGG_Pre 的 mode 做一次完整的 training，比較其結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference:\n",
    "* [使用 Tensorflow 實現類 VGG model 訓練 Cifar10 數據集](http://arbu00.blogspot.com/2018/03/7-tensorflowvgg-model-cifar10.html)\n",
    "* [Ashing00/Tensorflow_VGG](https://github.com/Ashing00/Tensorflow_VGG)\n",
    "  * vgg_inference.py\n",
    "    * VGG16 Class\n",
    "  * vgg_train.py\n",
    "    * Training Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [The CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "* 我們使用的是 CIFAR-10 binary version (suitable for C programs)。\n",
    "  * The binary version contains the files data_batch_1.bin, data_batch_2.bin, ..., data_batch_5.bin, as well as test_batch.bin. Each of these files is formatted as follows:\n",
    "```\n",
    "\t\t<1 x label><3072 x pixel>\n",
    "\t\t...\n",
    "\t\t<1 x label><3072 x pixel>\n",
    "```\n",
    "  * In other words, the first byte is the label of the first image, which is a number in the range 0-9. The next 3072 bytes are the values of the pixels of the image. The first 1024 bytes are the red channel values, the next 1024 the green, and the final 1024 the blue. The values are stored in row-major order, so the first 32 bytes are the red channel values of the first row of the image. \n",
    "  * Each file contains 10000 such 3073-byte \"rows\" of images, although there is nothing delimiting the rows. Therefore each file should be exactly 30730000 bytes long. \n",
    "  * There is another file, called batches.meta.txt. This is an ASCII file that maps numeric labels in the range 0-9 to meaningful class names. It is merely a list of the 10 class names, one per row. The class name on row i corresponds to numeric label i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ryanyao/work/my_ml_study/TensorFlow_Study/vgg16/vgg16_cifar10_train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download CIFAR-10 Dataset (binary version)\n",
    "* Move it to you source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !../get_cifar10.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import struct\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2,csv\n",
    "import vgg_inference\n",
    "\n",
    "data_dir = \"../../../data/\"\n",
    "extract_folder = 'cifar-10-batches-bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode_labels( y, k)\n",
    "* 將 label 轉成 one-shot 的形式\n",
    "* ex: 以此 10 分類來說，0 <= label <=9。若 label = 3，則其 one-shot 形式為 [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels( y, k):\n",
    "\t\"\"\"Encode labels into one-hot representation\n",
    "\t\"\"\"\n",
    "\tonehot = np.zeros((y.shape[0],k ))\n",
    "\tfor idx, val in enumerate(y):\n",
    "\t\tonehot[idx,val] = 1.0  ##idx=0~xxxxx，if val =3 ,表示欄位3要設成1.0\n",
    "\treturn onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以 binary read 的方式讀取 train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(n):\t\t\t#n=1,2..5,data_batch_1.bin ~data_batch_5.bin\n",
    "\t\"\"\"Load Cifar10 data from `path`\"\"\"\n",
    "\timages_path = os.path.join(data_dir, extract_folder, 'data_batch_{}.bin'.format(n)) \n",
    "\twith open(images_path, 'rb') as imgpath:\n",
    "\t\timages = np.fromfile(imgpath, dtype=np.uint8)\n",
    "\treturn images\n",
    "\t\n",
    "def load_test_data():\t\t\t#test_batch\n",
    "\t\"\"\"Load Cifar10 test data from `path`\"\"\"\n",
    "\ttest_path = os.path.join(data_dir, extract_folder, 'test_batch.bin') \n",
    "\twith open(test_path, 'rb') as testpath:\n",
    "\t\ttest_img = np.fromfile(testpath, dtype=np.uint8)\n",
    "\treturn test_img\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MODEL_SAVE_PATH = \"./vgg/\"\n",
    "MODEL_NAME = \"vgg_cifar_model\"\n",
    "learning_rate = 0.001\n",
    "BATCH_SIZE = 120\n",
    "display_step = 100\n",
    "TRAINING_STEPS=6000\n",
    "# Network Parameters\n",
    "n_input = 3072 # cifar data input (img shape: 32x32x3)\n",
    "n_classes = 10 # cifar10 total classes (0-9 )\n",
    "dropout = 0.60# Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 程序\n",
    "* shuffle\n",
    "  * 用來控制在 training 過程中，取 train set 的順序是循序或是隨機選取 (隨機選取的順序存在 train_idx)\n",
    "* vgg_inference\n",
    "  * 是 VGG16 model，實作在 vgg_inference.py\n",
    "* 過程中，批次處理 training，並每隔特定次數 (TRAINING_STEPS=6000) 記錄下 (loss, accuracy) 於結整後顯示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train,y_train_lable):\n",
    "\tshuffle=True\n",
    "\tbatch_idx=0\n",
    "\tbatch_len =int( X_train.shape[0]/BATCH_SIZE)\n",
    "\tprint(\"batch_len=\", batch_len) # 50000/120 = 416.6 => 416\n",
    "\ttrain_loss=[]\n",
    "\ttrain_acc=[]\n",
    "\ttrain_idx=np.random.permutation(batch_len)#打散btach_len=500 group\n",
    "\n",
    "\t# tf Graph input\n",
    "\tx_ = tf.placeholder(tf.float32, [None, n_input])\t\n",
    "\ty = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\tkeep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\tx = tf.reshape(x_, shape=[-1, 32, 32, 3])\n",
    "\n",
    "\t# Construct model\n",
    "\tpred =vgg_inference.inference(x,  keep_prob)\n",
    "\n",
    "\t# Define loss and optimizer\n",
    "\tcost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\toptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\t#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\t#GradientDescentOptimizer\n",
    "\t# Evaluate model\n",
    "\tcorrect_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\taccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\t# 初始化TensorFlow持久化類。\n",
    "\tsaver = tf.train.Saver()\n",
    "\t# Initializing the variables\n",
    "\tinit = tf.global_variables_initializer()\n",
    "\n",
    "\t# Launch the graph\n",
    "\twith tf.Session() as sess:\n",
    "\t\tsess.run(init)\n",
    "\t\tstep = 1\n",
    "\t\tprint (\"Start  training!\")\n",
    "\t\t# Keep training until reach max iterations:\n",
    "\t\twhile step\t< TRAINING_STEPS:\n",
    "\t\t\t#batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "\t\t\tif shuffle==True:\n",
    "\t\t\t\tbatch_shuffle_idx=train_idx[batch_idx]\n",
    "\t\t\t\tbatch_xs=X_train[batch_shuffle_idx*BATCH_SIZE:batch_shuffle_idx*BATCH_SIZE+BATCH_SIZE]\n",
    "\t\t\t\tbatch_ys=y_train_lable[batch_shuffle_idx*BATCH_SIZE:batch_shuffle_idx*BATCH_SIZE+BATCH_SIZE]\t\n",
    "\t\t\telse:\n",
    "\t\t\t\tbatch_xs=X_train[batch_idx*BATCH_SIZE:batch_idx*BATCH_SIZE+BATCH_SIZE]\n",
    "\t\t\t\tbatch_ys=y_train_lable[batch_idx*BATCH_SIZE:batch_idx*BATCH_SIZE+BATCH_SIZE]\n",
    "\t\t\n",
    "\t\t\tif batch_idx<batch_len:\n",
    "\t\t\t\tbatch_idx+=1\n",
    "\t\t\t\tif batch_idx==batch_len:\n",
    "\t\t\t\t\tbatch_idx=0\n",
    "\t\t\telse:\n",
    "\t\t\t\tbatch_idx=0\n",
    "\t\t\t# Ryan: why need the reshape?\n",
    "\t\t\treshaped_xs = np.reshape(batch_xs, (\n",
    "\t\t\t\t\tBATCH_SIZE,\n",
    "\t\t\t\t\t32,\n",
    "\t\t\t\t\t32,\n",
    "\t\t\t\t\t3))\n",
    "\t\t\t\n",
    "\t\t\t# Run optimization op (backprop)\n",
    "\t\t\tsess.run(optimizer, feed_dict={x: reshaped_xs, y: batch_ys,\n",
    "\t\t\t\t\t\t\t\t\t\tkeep_prob: dropout})\n",
    "\t\t\t# Calculate batch loss and accuracy\n",
    "\t\t\tloss, acc = sess.run([cost, accuracy], feed_dict={x: reshaped_xs,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ty: batch_ys,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tkeep_prob: 1.})\n",
    "\t\t\ttrain_loss.append(loss)\n",
    "\t\t\ttrain_acc.append(acc)\n",
    "\t\t\tif step % display_step == 0:\n",
    "\t\t\t\tprint(\"Step: \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "\t\t\t\t\t\"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "\t\t\t\t\t\"{:.5f}\".format(acc))\n",
    "\t\t\tstep += 1\n",
    "\t\tprint(\"Optimization Finished!\")\n",
    "\t\tprint(\"Save model...\")\n",
    "\t\t#saver.save(sess, \"./vgg/vgg_model\")\n",
    "\t\tsaver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME))\n",
    "\t\t\n",
    "\t\tplt.subplot(1,2,1)\n",
    "\t\tplt.plot(train_loss)\n",
    "\t\tplt.xlabel('Iter')\n",
    "\t\tplt.ylabel('loss')\n",
    "\t\tplt.title('lr=%f, ti=%d, bs=%d' % (learning_rate, TRAINING_STEPS, BATCH_SIZE))\n",
    "\t\t#plt.tight_layout()\n",
    "\n",
    "\t\tplt.subplot(1,2,2)\n",
    "\t\tplt.plot(train_acc)\n",
    "\t\tplt.xlabel('Iter')\n",
    "\t\tplt.ylabel('accuracy')\n",
    "\t\tplt.title('lr=%f, ti=%d, bs=%d' % (learning_rate, TRAINING_STEPS, BATCH_SIZE))\n",
    "\t\t#plt.tight_layout()\n",
    "\t\tplt.savefig('vgg_cifar10_acc.jpg', dpi=200)\n",
    "\t\tplt.show()\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主程序\n",
    "* X_train_image\n",
    "  * 一開始其 shape = (50000, 3073)，後來利用 np.delete() 將 lable 欄位移除，所以剩下 (50000, 3072)\n",
    "  * 所有的 train set, 共有 5000 筆。所以其 shape = (50000, 3072)\n",
    "    * 其中有一段，我們將 train_image 由 (50000, 3, 32, 32) trans position to ((50000, 32, 32, 3)，是為了符合 VGG16 原本的 data layout。\n",
    "    * CIFAR-10 data layout of a picture is (3, 32, 32) = (channel, length, width)\n",
    "    * VGG16 data layout of a picture is (224, 224, 3)= (length, width, channel)\n",
    "  * 有需要 trans position 嗎? 因為這是完整的訓練，跟原本 VGG16 從 ImageNet 取得的 data layout of picture 是無相關的?\n",
    "    * ToDo (Halt)\n",
    "      * `不要做 trans position，再試一次看結果如何?`\n",
    "* X_train_label\n",
    "  * 獨立取出的 lable 值放至此，初始時其 shape = (50000, )\n",
    "  * 經過 one-shot 處理後，其 shape= (50000, 10)\n",
    "* train(X_train_image,X_train_label)\n",
    "  * 進行 training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30730000,)\n",
      "(153650000,)\n",
      "y_train_lable.shape= (50000, 3072)\n",
      "(50000,)\n",
      "y_train_lable.shape= (50000, 10)\n",
      "batch_len= 416\n",
      "layer1-conv1/Relu   [None, 32, 32, 64]\n",
      "layer1-conv1/Relu_1   [None, 32, 32, 64]\n",
      "layer1-conv1/pool1   [None, 32, 32, 64]\n",
      "layer1-conv2/Relu   [None, 32, 32, 128]\n",
      "layer1-conv2/Relu_1   [None, 32, 32, 128]\n",
      "layer1-conv2/pool2   [None, 16, 16, 128]\n",
      "layer3-conv3/Relu   [None, 16, 16, 256]\n",
      "layer3-conv3/Relu_1   [None, 16, 16, 256]\n",
      "layer3-conv3/Relu_2   [None, 16, 16, 256]\n",
      "layer3-conv3/pool3   [None, 8, 8, 256]\n",
      "layer4-conv4/Relu   [None, 8, 8, 512]\n",
      "layer4-conv4/Relu_1   [None, 8, 8, 512]\n",
      "layer4-conv4/Relu_2   [None, 8, 8, 512]\n",
      "layer4-conv4/pool4   [None, 4, 4, 512]\n",
      "layer5-conv5/Relu   [None, 4, 4, 512]\n",
      "layer5-conv5/Relu_1   [None, 4, 4, 512]\n",
      "layer5-conv5/Relu_2   [None, 4, 4, 512]\n",
      "layer5-conv5/pool5   [None, 2, 2, 512]\n",
      "layer6-fc1/Relu   [None, 4096]\n",
      "layer7-fc2/Relu   [None, 4096]\n",
      "WARNING:tensorflow:From <ipython-input-7-d4195b08c7b3>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Start  training!\n",
      "Step: 100, Minibatch Loss= 1.657398, Training Accuracy= 0.45833\n",
      "Step: 200, Minibatch Loss= 1.267138, Training Accuracy= 0.55000\n",
      "Step: 300, Minibatch Loss= 1.351522, Training Accuracy= 0.53333\n",
      "Step: 400, Minibatch Loss= 2.011864, Training Accuracy= 0.63333\n",
      "Step: 500, Minibatch Loss= 1.339228, Training Accuracy= 0.58333\n",
      "Step: 600, Minibatch Loss= 1.532635, Training Accuracy= 0.55000\n",
      "Step: 700, Minibatch Loss= 1.185099, Training Accuracy= 0.58333\n",
      "Step: 800, Minibatch Loss= 1.144912, Training Accuracy= 0.70000\n",
      "Step: 900, Minibatch Loss= 1.070196, Training Accuracy= 0.63333\n",
      "Step: 1000, Minibatch Loss= 1.183576, Training Accuracy= 0.68333\n",
      "Step: 1100, Minibatch Loss= 1.188945, Training Accuracy= 0.69167\n",
      "Step: 1200, Minibatch Loss= 1.122861, Training Accuracy= 0.70833\n",
      "Step: 1300, Minibatch Loss= 0.910570, Training Accuracy= 0.77500\n",
      "Step: 1400, Minibatch Loss= 0.915803, Training Accuracy= 0.70000\n",
      "Step: 1500, Minibatch Loss= 0.788396, Training Accuracy= 0.79167\n",
      "Step: 1600, Minibatch Loss= 0.806435, Training Accuracy= 0.72500\n",
      "Step: 1700, Minibatch Loss= 0.624505, Training Accuracy= 0.74167\n",
      "Step: 1800, Minibatch Loss= 0.647151, Training Accuracy= 0.80000\n",
      "Step: 1900, Minibatch Loss= 0.891373, Training Accuracy= 0.71667\n",
      "Step: 2000, Minibatch Loss= 0.718232, Training Accuracy= 0.74167\n",
      "Step: 2100, Minibatch Loss= 0.364719, Training Accuracy= 0.88333\n",
      "Step: 2200, Minibatch Loss= 0.431879, Training Accuracy= 0.88333\n",
      "Step: 2300, Minibatch Loss= 0.471254, Training Accuracy= 0.80000\n",
      "Step: 2400, Minibatch Loss= 0.410451, Training Accuracy= 0.83333\n",
      "Step: 2500, Minibatch Loss= 0.300637, Training Accuracy= 0.90000\n",
      "Step: 2600, Minibatch Loss= 0.394378, Training Accuracy= 0.85833\n",
      "Step: 2700, Minibatch Loss= 0.383829, Training Accuracy= 0.86667\n",
      "Step: 2800, Minibatch Loss= 0.304092, Training Accuracy= 0.91667\n",
      "Step: 2900, Minibatch Loss= 0.356742, Training Accuracy= 0.90000\n",
      "Step: 3000, Minibatch Loss= 0.157097, Training Accuracy= 0.96667\n",
      "Step: 3100, Minibatch Loss= 0.203666, Training Accuracy= 0.94167\n",
      "Step: 3200, Minibatch Loss= 0.234246, Training Accuracy= 0.92500\n",
      "Step: 3300, Minibatch Loss= 0.223790, Training Accuracy= 0.92500\n",
      "Step: 3400, Minibatch Loss= 0.193118, Training Accuracy= 0.94167\n",
      "Step: 3500, Minibatch Loss= 0.192480, Training Accuracy= 0.94167\n",
      "Step: 3600, Minibatch Loss= 0.075398, Training Accuracy= 0.99167\n",
      "Step: 3700, Minibatch Loss= 0.113010, Training Accuracy= 0.96667\n",
      "Step: 3800, Minibatch Loss= 0.089136, Training Accuracy= 0.98333\n",
      "Step: 3900, Minibatch Loss= 0.219494, Training Accuracy= 0.95000\n",
      "Step: 4000, Minibatch Loss= 0.130147, Training Accuracy= 0.98333\n",
      "Step: 4100, Minibatch Loss= 0.143771, Training Accuracy= 0.95833\n",
      "Step: 4200, Minibatch Loss= 0.089477, Training Accuracy= 0.97500\n",
      "Step: 4300, Minibatch Loss= 0.066354, Training Accuracy= 0.98333\n",
      "Step: 4400, Minibatch Loss= 0.105555, Training Accuracy= 0.96667\n",
      "Step: 4500, Minibatch Loss= 0.085052, Training Accuracy= 1.00000\n",
      "Step: 4600, Minibatch Loss= 0.085236, Training Accuracy= 0.98333\n",
      "Step: 4700, Minibatch Loss= 0.057195, Training Accuracy= 0.99167\n",
      "Step: 4800, Minibatch Loss= 0.056108, Training Accuracy= 0.98333\n",
      "Step: 4900, Minibatch Loss= 0.093461, Training Accuracy= 0.95833\n",
      "Step: 5000, Minibatch Loss= 0.086423, Training Accuracy= 0.98333\n",
      "Step: 5100, Minibatch Loss= 0.059087, Training Accuracy= 0.98333\n",
      "Step: 5200, Minibatch Loss= 0.011851, Training Accuracy= 1.00000\n",
      "Step: 5300, Minibatch Loss= 0.091217, Training Accuracy= 0.97500\n",
      "Step: 5400, Minibatch Loss= 0.089363, Training Accuracy= 0.97500\n",
      "Step: 5500, Minibatch Loss= 0.036892, Training Accuracy= 1.00000\n",
      "Step: 5600, Minibatch Loss= 0.014255, Training Accuracy= 1.00000\n",
      "Step: 5700, Minibatch Loss= 0.050615, Training Accuracy= 0.98333\n",
      "Step: 5800, Minibatch Loss= 0.042577, Training Accuracy= 1.00000\n",
      "Step: 5900, Minibatch Loss= 0.016170, Training Accuracy= 0.99167\n",
      "Optimization Finished!\n",
      "Save model...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def vgg_train(argv=None):\n",
    "\n",
    "\t##Load Cifar-10 train image and label\t\n",
    "\tX_train_image1 = load_train_data(1)\t#load data_batch_1.bin\n",
    "\tX_train_image2 = load_train_data(2)\t#load data_batch_2.bin\n",
    "\tX_train_image3 = load_train_data(3)\t#load data_batch_3.bin\n",
    "\tX_train_image4 = load_train_data(4)\t#load data_batch_4.bin\n",
    "\tX_train_image5 = load_train_data(5)\t#load data_batch_5.bin\n",
    "\tprint(X_train_image1.shape) # (30730000,)\n",
    "\t\n",
    "\tX_train_image=np.concatenate((X_train_image1,X_train_image2,X_train_image3,X_train_image4,X_train_image5),axis=0)\n",
    "\tprint(X_train_image.shape) # (153650000,)\n",
    "\t\n",
    "\t#reshape to (50000,3073)\n",
    "\t#in one Row ,the 1st byte is the label,other 3072byte =1024 Red +1024 green +1024 blue ch data\n",
    "\tX_train_image = X_train_image.reshape(-1,3073)\n",
    "\ttempA = X_train_image.copy()\n",
    "\tX_train_image = np.delete(X_train_image, 0, 1) # delete 1st column data. (obj=0, axis=1)\n",
    "\tX_train_image = X_train_image.reshape(-1,3,32,32)  # reshape to (50000,3,32,32)\n",
    "\tX_train_image = X_train_image.transpose([0, 2, 3, 1])\t# transfer to (50000,32,32,3)\n",
    "\tX_train_image = X_train_image.reshape(-1,3072)  # (50000, 3072)\n",
    "\n",
    "\t#split to 3073 col,the first column is the label.\n",
    "\ttempA=np.hsplit(tempA,3073)\t\n",
    "\tX_train_label=np.asarray(tempA[0])\n",
    "\tX_train_label=X_train_label.reshape([50000,]) # (50000,)\n",
    "\n",
    "\tprint(\"y_train_lable.shape=\", X_train_image.shape)\t\n",
    "\tprint(X_train_label.shape)\t\n",
    "\t#print(X_train_label[0:50])\t\n",
    "\t\n",
    "\n",
    "\tX_train_label = encode_labels(X_train_label,10)\n",
    "\tprint(\"y_train_lable.shape=\",X_train_label.shape)\n",
    "\t#print(X_train_label[0:50])\t\n",
    "\t##============================\n",
    "\t\n",
    "\ttrain(X_train_image,X_train_label)\n",
    "\n",
    "vgg_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate with full test dataset\n",
    "* 上例的 accuracy 是由 train dataset 計算出來的，不客觀。\n",
    "* 用以下 vgg_eval() 來計算目前 trained VGG_Train，並以 test dataset 為 input。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_image.shape= (10000, 3072)\n",
      "X_test_label.shape= (10000, 10)\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "layer1-conv1/Relu   [None, 32, 32, 64]\n",
      "layer1-conv1/Relu_1   [None, 32, 32, 64]\n",
      "layer1-conv1/pool1   [None, 32, 32, 64]\n",
      "layer1-conv2/Relu   [None, 32, 32, 128]\n",
      "layer1-conv2/Relu_1   [None, 32, 32, 128]\n",
      "layer1-conv2/pool2   [None, 16, 16, 128]\n",
      "layer3-conv3/Relu   [None, 16, 16, 256]\n",
      "layer3-conv3/Relu_1   [None, 16, 16, 256]\n",
      "layer3-conv3/Relu_2   [None, 16, 16, 256]\n",
      "layer3-conv3/pool3   [None, 8, 8, 256]\n",
      "layer4-conv4/Relu   [None, 8, 8, 512]\n",
      "layer4-conv4/Relu_1   [None, 8, 8, 512]\n",
      "layer4-conv4/Relu_2   [None, 8, 8, 512]\n",
      "layer4-conv4/pool4   [None, 4, 4, 512]\n",
      "layer5-conv5/Relu   [None, 4, 4, 512]\n",
      "layer5-conv5/Relu_1   [None, 4, 4, 512]\n",
      "layer5-conv5/Relu_2   [None, 4, 4, 512]\n",
      "layer5-conv5/pool5   [None, 2, 2, 512]\n",
      "layer6-fc1/Relu   [None, 4096]\n",
      "layer7-fc2/Relu   [None, 4096]\n",
      "INFO:tensorflow:Restoring parameters from ./vgg/vgg_cifar_model\n",
      "Test  batch  0 :Testing Accuracy: 0.825\n",
      "Test  batch  1 :Testing Accuracy: 0.84166664\n",
      "Test  batch  2 :Testing Accuracy: 0.825\n",
      "Test  batch  3 :Testing Accuracy: 0.81666666\n",
      "Test  batch  4 :Testing Accuracy: 0.85\n",
      "Test  batch  5 :Testing Accuracy: 0.81666666\n",
      "Test  batch  6 :Testing Accuracy: 0.75\n",
      "Test  batch  7 :Testing Accuracy: 0.81666666\n",
      "Test  batch  8 :Testing Accuracy: 0.7916667\n",
      "Test  batch  9 :Testing Accuracy: 0.8333333\n",
      "Test  batch  10 :Testing Accuracy: 0.8666667\n",
      "Test  batch  11 :Testing Accuracy: 0.80833334\n",
      "Test  batch  12 :Testing Accuracy: 0.76666665\n",
      "Test  batch  13 :Testing Accuracy: 0.80833334\n",
      "Test  batch  14 :Testing Accuracy: 0.78333336\n",
      "Test  batch  15 :Testing Accuracy: 0.85\n",
      "Test  batch  16 :Testing Accuracy: 0.7416667\n",
      "Test  batch  17 :Testing Accuracy: 0.84166664\n",
      "Test  batch  18 :Testing Accuracy: 0.81666666\n",
      "Test  batch  19 :Testing Accuracy: 0.81666666\n",
      "Test  batch  20 :Testing Accuracy: 0.7916667\n",
      "Test  batch  21 :Testing Accuracy: 0.78333336\n",
      "Test  batch  22 :Testing Accuracy: 0.85833335\n",
      "Test  batch  23 :Testing Accuracy: 0.80833334\n",
      "Test  batch  24 :Testing Accuracy: 0.8333333\n",
      "Test  batch  25 :Testing Accuracy: 0.76666665\n",
      "Test  batch  26 :Testing Accuracy: 0.80833334\n",
      "Test  batch  27 :Testing Accuracy: 0.825\n",
      "Test  batch  28 :Testing Accuracy: 0.8\n",
      "Test  batch  29 :Testing Accuracy: 0.7916667\n",
      "Test  batch  30 :Testing Accuracy: 0.775\n",
      "Test  batch  31 :Testing Accuracy: 0.76666665\n",
      "Test  batch  32 :Testing Accuracy: 0.775\n",
      "Test  batch  33 :Testing Accuracy: 0.80833334\n",
      "Test  batch  34 :Testing Accuracy: 0.8333333\n",
      "Test  batch  35 :Testing Accuracy: 0.84166664\n",
      "Test  batch  36 :Testing Accuracy: 0.85833335\n",
      "Test  batch  37 :Testing Accuracy: 0.7916667\n",
      "Test  batch  38 :Testing Accuracy: 0.81666666\n",
      "Test  batch  39 :Testing Accuracy: 0.78333336\n",
      "Test  batch  40 :Testing Accuracy: 0.85833335\n",
      "Test  batch  41 :Testing Accuracy: 0.80833334\n",
      "Test  batch  42 :Testing Accuracy: 0.8\n",
      "Test  batch  43 :Testing Accuracy: 0.7916667\n",
      "Test  batch  44 :Testing Accuracy: 0.84166664\n",
      "Test  batch  45 :Testing Accuracy: 0.85833335\n",
      "Test  batch  46 :Testing Accuracy: 0.7416667\n",
      "Test  batch  47 :Testing Accuracy: 0.8333333\n",
      "Test  batch  48 :Testing Accuracy: 0.81666666\n",
      "Test  batch  49 :Testing Accuracy: 0.7916667\n",
      "Test  batch  50 :Testing Accuracy: 0.85833335\n",
      "Test  batch  51 :Testing Accuracy: 0.7583333\n",
      "Test  batch  52 :Testing Accuracy: 0.85833335\n",
      "Test  batch  53 :Testing Accuracy: 0.7583333\n",
      "Test  batch  54 :Testing Accuracy: 0.76666665\n",
      "Test  batch  55 :Testing Accuracy: 0.875\n",
      "Test  batch  56 :Testing Accuracy: 0.7916667\n",
      "Test  batch  57 :Testing Accuracy: 0.8\n",
      "Test  batch  58 :Testing Accuracy: 0.775\n",
      "Test  batch  59 :Testing Accuracy: 0.7416667\n",
      "Test  batch  60 :Testing Accuracy: 0.85\n",
      "Test  batch  61 :Testing Accuracy: 0.78333336\n",
      "Test  batch  62 :Testing Accuracy: 0.81666666\n",
      "Test  batch  63 :Testing Accuracy: 0.825\n",
      "Test  batch  64 :Testing Accuracy: 0.8\n",
      "Test  batch  65 :Testing Accuracy: 0.76666665\n",
      "Test  batch  66 :Testing Accuracy: 0.78333336\n",
      "Test  batch  67 :Testing Accuracy: 0.80833334\n",
      "Test  batch  68 :Testing Accuracy: 0.7083333\n",
      "Test  batch  69 :Testing Accuracy: 0.76666665\n",
      "Test  batch  70 :Testing Accuracy: 0.78333336\n",
      "Test  batch  71 :Testing Accuracy: 0.7916667\n",
      "Test  batch  72 :Testing Accuracy: 0.7916667\n",
      "Test  batch  73 :Testing Accuracy: 0.76666665\n",
      "Test  batch  74 :Testing Accuracy: 0.775\n",
      "Test  batch  75 :Testing Accuracy: 0.825\n",
      "Test  batch  76 :Testing Accuracy: 0.81666666\n",
      "Test  batch  77 :Testing Accuracy: 0.80833334\n",
      "Test  batch  78 :Testing Accuracy: 0.75\n",
      "Test  batch  79 :Testing Accuracy: 0.8\n",
      "Test  batch  80 :Testing Accuracy: 0.85\n",
      "Test  batch  81 :Testing Accuracy: 0.775\n",
      "Test  batch  82 :Testing Accuracy: 0.84166664\n",
      "Average Testing Accuracy= 0.80471885\n"
     ]
    }
   ],
   "source": [
    "def evaluate(X_test,y_test_lable):\n",
    "\twith tf.Graph().as_default() as g:\n",
    "\t\n",
    "\t\t# 定義輸出為4維矩陣的placeholder\n",
    "\t\tx_ = tf.placeholder(tf.float32, [None, n_input])\t\n",
    "\t\tx = tf.reshape(x_, shape=[-1, 32, 32, 3])\n",
    "\t\ty = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\t\n",
    "\t\t# Construct model\n",
    "\t\tpred = vgg_inference.inference(x, 1)     #dropout=1\n",
    "\n",
    "\t\t# Evaluate model\n",
    "\t\tcorrect_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\t\taccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\t\n",
    "\t\ttest_batch_len =int( X_test.shape[0]/BATCH_SIZE)\n",
    "\t\ttest_acc=[]\n",
    "\t\t\n",
    "\t\ttest_xs = np.reshape(X_test, (\n",
    "\t\t\t\t\tX_test.shape[0],\n",
    "\t\t\t\t\t32,\n",
    "\t\t\t\t\t32,\n",
    "\t\t\t\t\t3))\n",
    "\t\t\n",
    "\t\tbatchsize = BATCH_SIZE\n",
    "\t\n",
    "\t\t# 'Saver' op to save and restore all the variables\n",
    "\t\tsaver = tf.train.Saver()\n",
    "\t\twith tf.Session() as sess:\n",
    "\t\t\tsaver.restore(sess,\"./vgg/vgg_cifar_model\")\n",
    "\n",
    "\t\t\tfor i in range(test_batch_len):\n",
    "\t\t\t\ttemp_acc= sess.run(accuracy, feed_dict={x: test_xs[batchsize*i:batchsize*i+batchsize], y: y_test_lable[batchsize*i:batchsize*i+batchsize]})\n",
    "\t\t\t\ttest_acc.append(temp_acc)\n",
    "\t\t\t\tprint (\"Test  batch \",i,\":Testing Accuracy:\",temp_acc)\t\n",
    "\n",
    "\t\t\tt_acc=tf.reduce_mean(tf.cast(test_acc, tf.float32))\t\n",
    "\t\t\tprint(\"Average Testing Accuracy=\",sess.run(t_acc))\n",
    "\t\t\treturn\n",
    "\n",
    "def vgg_eval(argv=None):\n",
    "\n",
    "\t##Load Cifar-10 test image  and label\t\n",
    "\tX_test_image = load_test_data()\t#load test_batch.bin\n",
    "\t#reshape to (10000,3073)\n",
    "\t#in one Row ,the 1st byte is the label,other 3072byte =1024 Red +1024 green +1024 blue ch data\n",
    "\tX_test_image=X_test_image.reshape(-1,3073)\n",
    "\ttempA=X_test_image.copy()\n",
    "\tX_test_image=np.delete(X_test_image, 0, 1) #delete 1st column data\n",
    "\tX_test_image=X_test_image.reshape(-1,3,32,32)  #(1000,3,32,32)\n",
    "\tX_test_image = X_test_image.transpose([0, 2, 3, 1])\t#transfer to (10000,32,32,3)\n",
    "\tX_test_image=X_test_image.reshape(-1,3072)  #(50000,3,32,32)\n",
    "\n",
    "\t#split to 3073 col,the first column is the label.\n",
    "\ttempA=np.hsplit(tempA,3073)\t\n",
    "\tX_test_label=np.asarray(tempA[0])\n",
    "\tX_test_label=X_test_label.reshape([10000,])\n",
    "\n",
    "\t\n",
    "\t#mms=MinMaxScaler()\n",
    "\t#X_test_image=mms.fit_transform(X_test_image)\n",
    "\t\n",
    "\tX_test_label = encode_labels(X_test_label,10)\n",
    "\t\n",
    "\t\n",
    "\tprint(\"X_test_image.shape=\",X_test_image.shape)\t\n",
    "\tprint(\"X_test_label.shape=\",X_test_label.shape)\n",
    "\tprint(X_test_label[0:5])\t\n",
    "\t\n",
    "\n",
    "\t\n",
    "\tevaluate(X_test_image,X_test_label)\n",
    "\n",
    "vgg_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "\n",
    "* Batch Normalization\n",
    "  * [批标准化 (Batch Normalization)](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-08-batch-normalization/)\n",
    "  * [Batch Normalization](http://violin-tao.blogspot.com/2018/02/ml-batch-normalization.html)\n",
    "  * [谈谈Tensorflow的Batch Normalization](https://www.jianshu.com/p/0312e04e4e83)\n",
    "\n",
    "* [tf.nn.softmax_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits)\n",
    "  * [tf.nn.softmax_cross_entropy_with_logits的用法](https://blog.csdn.net/mao_xiao_feng/article/details/53382790)\n",
    "\n",
    "* np.concatenate()\n",
    "  * [numpy库数组拼接np.concatenate官方文档详解与实例](https://blog.csdn.net/brucewong0516/article/details/79158758)\n",
    "  \n",
    "* np.delete()\n",
    "  * [numpy.delete刪除一列或多列的方法](https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/358343/)\n",
    "  \n",
    "* np.copy()\n",
    "  * [numpy 中的 copy 问题详解](https://blog.csdn.net/u010099080/article/details/59111207)\n",
    "  \n",
    "* numpy.random.permutation()\n",
    "  * [numpy.random.permutation](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.permutation.html)\n",
    "  \n",
    "* tf.train.Saver()\n",
    "  * [使用 tf.train.Saver()保存模型](https://blog.csdn.net/Jerr__y/article/details/78594494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
