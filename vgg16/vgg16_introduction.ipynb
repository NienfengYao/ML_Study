{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic\n",
    "* DataSet\n",
    "* [VGG-16 Architecture](#VGG-16-Architecture)\n",
    "* [VGG-16 in TensorFlow](#VGG-16-in-TensorFlow)\n",
    "* [VGG-16 in Keras](#VGG-16-in-Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet\n",
    "* [ImageNet ILSVRC2012](http://www.image-net.org/challenges/LSVRC/2012/)\n",
    "  * The 1000 object categories\n",
    "  * The training data is 1.2 million images\n",
    "  * The validation data is 50k images.\n",
    "  * The test data is 100k images.\n",
    "  * Where to download the dataset?\n",
    "    * [How to Create Imagenet ILSVRC2012 LMDB](https://github.com/rioyokotalab/caffe/wiki/How-to-Create-Imagenet-ILSVRC2012-LMDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 Architecture\n",
    "* Paper: [VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION](https://arxiv.org/pdf/1409.1556.pdf)\n",
    "* Input: 224 x 224 RGB image\n",
    "  * Processing: Subtracting the mean RGB value, computed on the trainint set, from each pixel.\n",
    "* Convolutional\n",
    "  * receptive filters: 3 x 3\n",
    "  * stride: 1\n",
    "  * utilise 1 x 1 convolution filters, wihic can be seen as a linear transformation of the input channels. \n",
    "    * 這是 ConvNet Configuration = C 時才有用到。其餘的 config 並沒有使用。\n",
    "  * padding is 1 for 3 x 3 conv.layer. The spatial resolution is preserved after convolution.\n",
    "* Pooling\n",
    "  * Max-pooling is performed over a 2 x 2 pixel window, with stride 2\n",
    "* 3 Fully-Connected(FC) layers:\n",
    "  * the first two have 4096 channels each\n",
    "  * the third performs 1000 classification with soft-max\n",
    "* The rectification is ReLU\n",
    "* 實驗過程\n",
    "  * 在當初作者實作是使用 C++ Caffet，並用4個 Nvidia Titan Black GPU training 模型。每一個 Model 實驗，都要跑 2–3 周。\n",
    "  * 為縮短 training 時間，VGG 在實驗過程有使用 transfer learning，BCDE模型的前四個 Conv 以及 FC 的 weight 將使用已經訓練好的 A 做為initial，其他沒有被 A inital的就由模型自行學習。\n",
    "* Architecute: ![alt text](VGG-16_Architecture.png \"Architecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 in TensorFlow\n",
    "* 使用已經訓練完的 VGG16 模型，在 Tensorflow 上直接進行圖片預測. \n",
    "  * [vgg16_pretrained_predict.ipynb](vgg16_pretrained_predict.ipynb)\n",
    "* 利用 CIFAR-10 dataset，使用 VGG16 模型進行 training. \n",
    "  * [vgg-cifar10_train.ipynb](vgg16/vgg-cifar10_train.ipynb)\n",
    "  * 在 training procedure 中，其 accuracy 是由 train dataset 所計算出來的，不客觀。\n",
    "  * 在最後，vgg_eval() 計算了由 test dataset 得出的 accuracy = 82%\n",
    "* 利用 CIFAR-10 dataset，使用 VGG16 模型進行 transfer learning (Failed)\n",
    "  * Reference [deep-diver/CIFAR10-VGG19-Tensorflow](https://github.com/deep-diver/CIFAR10-VGG19-Tensorflow)，並無法執行。主要原因是因為在 training 時，會發生 out of memory 的現象，即使 mark accuracy 的量測部份還是如此。\n",
    "* VGG16 transfer learning example. \n",
    "  * [Transfer_Learning.ipynb](transfer-learning/Transfer_Learning.ipynb)\n",
    "  * 主要是保持前五層 Conv 不變，移除掉後三層的 FC + output layer，新增自己的 classifier layer (FC + output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 in Keras\n",
    "* Using a pre-trained model(VGG16) in Keras. ([keras_pre-trained_vgg16.ipynb](keras_pre-trained_vgg16.ipynb))\n",
    "  * Classify ImageNet classes\n",
    "  * Extract the feature of a given image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference:\n",
    "* [ILSVRC 歷屆的深度學習模型](https://chtseng.wordpress.com/2017/11/20/ilsvrc-%E6%AD%B7%E5%B1%86%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B/)\n",
    "  * 內含模型結構資訊比較\n",
    "    * Top-1表示只預測一次且正確的機率。\n",
    "    * Top-5表示預測五次只要一次猜對就算正確的機率。\n",
    "    * Size：記憶體的最高佔據量。\n",
    "    * Parameters：參數的數量，愈多就須計算愈久。\n",
    "    * Depth：filters的數目。\n",
    "* [Day 09：CNN 經典模型應用](https://ithelp.ithome.com.tw/articles/10192162)\n",
    "* [入門深度學習—2 解析 CNN 演算法](https://medium.com/@syshen/%E5%85%A5%E9%96%80%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-2-d694cad7d1e5)\n",
    "  * [如何通俗易懂地解释卷积？](https://www.zhihu.com/question/22298352)\n",
    "* [Paper: Very Deep Convolutional Networks For Large-Scale Image Recognition](https://arxiv.org/pdf/1409.1556v6.pdf)\n",
    "  * [從零開始構建VGG網絡來學習 Keras](https://github.com/erhwenkuo/deep-learning-with-keras-notebooks/blob/master/1.2-vgg16-from-scratch.ipynb)\n",
    "  * [VGG_深度學習_原理](https://medium.com/@danjtchen/vgg-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E5%8E%9F%E7%90%86-d31d0aa13d88)\n",
    "  \n",
    "* [Deep Learning與影像風格轉換](http://www.cc.ntu.edu.tw/chinese/epaper/0042/20170920_4206.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
