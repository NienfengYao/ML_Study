{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference:\n",
    "* LeNet-5\n",
    "  * [卷积神经网络Lenet-5详解](https://blog.csdn.net/d5224/article/details/68928083)\n",
    "    * 這裡說明是用 Max Pooling, 並未提及 activation function 是用何者\n",
    "  * [LeNet-5, convolutional neural networks](http://yann.lecun.com/exdb/lenet/)\n",
    "    * LeNet-5 is our latest convolutional network designed for handwritten and machine-printed character recognition.\n",
    "  * [LeNet-5 - A Classic CNN Architecture](https://engmrk.com/lenet-5-a-classic-cnn-architecture/)\n",
    "    * 這裡說明是用 Avg Pooling, activation function 是 tanh 和 softmax\n",
    "  * [PyTorch Taipei 2018 week1: LeNet-5](https://mattwang44.github.io/en/articles/PyTorchTP-LeNet/)\n",
    "    * LeNet-5 介紹，詳盡的說明\n",
    "  * [keras/examples/mnist_cnn.py](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)\n",
    "    * 一個 CNN model，以 MNIST 為 dataset 的 example。以下實作的架構主要是參考此文  \n",
    "  * [Netscope CNN Analyzer](https://dgschwend.github.io/netscope/quickstart.html)\n",
    "    * 分析計算 CNN 的 operation 次數\n",
    "  \n",
    "* Dataset: MNIST\n",
    "  * [Keras Documents: MNIST database of handwritten digits](https://keras.io/datasets/)\n",
    "  * [THE MNIST DATABASE of handwritten digits](http://yann.lecun.com/exdb/mnist/)  \n",
    "  \n",
    "  \n",
    "* Issues:\n",
    "  * Wrokaround [Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR](https://github.com/tensorflow/tensorflow/issues/24496)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "* Input Image: 28x28 (非原本 paper 的 32x32)\n",
    "  * 將 pixel value 從 0~255 轉換成從 0.0~1.0\n",
    "* Convolution (C1)\n",
    "  * Filter: 6@5x5\n",
    "  * Feature map: 6@28x28\n",
    "  * \n",
    "* Pooling (S2)\n",
    "* Convolution (C3)\n",
    "* Pooling (S4)\n",
    "* Convolution (C5)\n",
    "* Fully-connected (F6)\n",
    "* Output: Fully-connected (F7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_data_format() =  channels_last\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.2853 - acc: 0.9118 - val_loss: 0.0621 - val_acc: 0.9805\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0903 - acc: 0.9730 - val_loss: 0.0424 - val_acc: 0.9849\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0668 - acc: 0.9796 - val_loss: 0.0365 - val_acc: 0.9871\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0559 - acc: 0.9834 - val_loss: 0.0314 - val_acc: 0.9883\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0471 - acc: 0.9857 - val_loss: 0.0289 - val_acc: 0.9901\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0418 - acc: 0.9874 - val_loss: 0.0291 - val_acc: 0.9899\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0388 - acc: 0.9882 - val_loss: 0.0290 - val_acc: 0.9898\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0329 - acc: 0.9897 - val_loss: 0.0287 - val_acc: 0.9905\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0301 - acc: 0.9907 - val_loss: 0.0263 - val_acc: 0.9915\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0290 - acc: 0.9913 - val_loss: 0.0274 - val_acc: 0.9910\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0281 - acc: 0.9912 - val_loss: 0.0275 - val_acc: 0.9907\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0262 - acc: 0.9918 - val_loss: 0.0235 - val_acc: 0.9918\n",
      "Test loss: 0.023531104733187022\n",
      "Test accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"K.image_data_format() = \", K.image_data_format())\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Workaround Issue: \"Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分析計算量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Layer | Ops |  Output|\n",
    "|------|------|------|\n",
    "| Image | None | 28x28 | \n",
    "| conv2d_1(32@3x3) | 32x(26x26)x(3x3x1)=194,688 macc | 32x(26x26) |\n",
    "| relu | 32x(26x26)=21,632 comp | 32x(26x26) |\n",
    "| conv2d_2(64@3x3) | 64x(24x24)x(3x3x1)=331,776 macc | 64x(24x24) |\n",
    "| relu | 64x(24x24)=36,864 comp | 64x(24x24) |\n",
    "| max_pooling2d_1(2x2) | 64x(12x12)x(2x2x1)=36,864 comp | 64x(12x12) |\n",
    "| dropout_1(0.25) | None | 64x(12x12) |\n",
    "| flatten_1 | None | 64x12x12 |\n",
    "| dense_1(128) | 64x12x12x128=1197648 macc | 128 |\n",
    "| dropout_2(0.25) | None | 128 |\n",
    "| dense_2(10) | 128x10=1,280 macc | 10 |\n",
    "| softmax | 10 softmax | 10 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
