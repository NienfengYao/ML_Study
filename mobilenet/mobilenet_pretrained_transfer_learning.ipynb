{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained MobileNet do transfer learning\n",
    "下載 Keras-MobileNet model, using [Kaggle: Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/) dataset to do transfer learning.  \n",
    "* [整理資料集](#%E6%95%B4%E7%90%86%E8%B3%87%E6%96%99%E9%9B%86)\n",
    "  * 原本 training set 共有 25,000 筆，在此只取 6,000 筆資料來學習 (目前取用全部資料時，執行時間過長)\n",
    "    * training images: 4000\n",
    "    * validation images: 1000\n",
    "    * test images: 1000\n",
    "* [圖片預處理](#%E5%9C%96%E7%89%87%E9%A0%90%E8%99%95%E7%90%86)\n",
    "  * ImageDataGenerator().flow_from_directory()\n",
    "  * 需要 rescale 嗎? 目前沒做\n",
    "* [Transfer-Learning](#Transfer-Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "* [Transfer Learning with Keras！](https://ithelp.ithome.com.tw/articles/10190971)\n",
    "* [Transfer learning from pre-trained models](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751)\n",
    "  * 如何將下載的資料整理成適當的目錄結構以供 ImageDataGenerator 使用。\n",
    "* [keras_applications/mobilenet.py](https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet.py)\n",
    "  * MobileNet model source code\n",
    "* [Keras: MobileNet](https://keras.io/applications/#mobilenet)\n",
    "  * Keras MobileNet class usage\n",
    "* [Transfer Learning using Mobilenet and Keras](https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299)\n",
    "* [Keras 以 ResNet-50 預訓練模型建立狗與貓辨識程式](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)\n",
    "* 基於Keras實現Kaggle2013–Dogs vs. Cats12500張貓狗影象的精準分類(https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/456610/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\n",
      "TensorFlow: 1.13.1\n",
      "Keras: 2.2.4\n",
      "NVIDIA-SMI 415.27       Driver Version: 415.27       CUDA Version: 10.0     |\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "!python --version\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "!nvidia-smi | grep Version | cut -c 3-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround Issue: \"Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\"\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理資料集\n",
    "* 從 [Kaggle: Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/) 下載資料\n",
    "* 建立好目錄結構  \n",
    "  * train (各2,000張) \n",
    "    * cats  \n",
    "    * dogs  \n",
    "  * valid (各500張)    \n",
    "    * cats\n",
    "    * dogs  \n",
    "  * test (各500張)    \n",
    "    * cats\n",
    "    * dogs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "# import os, shutil, glob\n",
    "\n",
    "sour_dir = '/home/ryanyao/docker_mount/data/dogs_vs_cats'\n",
    "dest_dir = '/home/ryanyao/docker_mount/data/dogs_vs_cats_dir'\n",
    "# 目前 test 目錄未使用\n",
    "step_set = ('train', 'valid', 'test')\n",
    "class_set = ('cats', 'dogs')\n",
    "class_fname_set = ('cat', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dest_dir):\n",
    "    os.mkdir(dest_dir)\n",
    "\n",
    "# Create directories\n",
    "for i_set in step_set:\n",
    "    set_dir = os.path.join(dest_dir, i_set)\n",
    "    if not os.path.exists(set_dir):\n",
    "        os.mkdir(set_dir)\n",
    "    for i_class in class_set:\n",
    "        class_dir = os.path.join(set_dir, i_class)\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.mkdir(class_dir)\n",
    "\n",
    "# # Copy all cat/dog images to train_dir\n",
    "# for i_idx, i_class in enumerate(['cat', 'dog']):\n",
    "#     sour_path = (os.path.join(sour_dir, step_set[0], i_class+\"*.jpg\"))\n",
    "#     fnames = glob.glob(sour_path)\n",
    "#     for fname in fnames:\n",
    "#         dst = os.path.join(dest_dir, step_set[0], class_set[i_idx], os.path.basename(fname))\n",
    "#         shutil.copyfile(fname, dst)                                 \n",
    "\n",
    "# Copy 3000 cat/dog images to train_dir\n",
    "for i_idx, i_class in enumerate(class_fname_set):\n",
    "    fname_pattern = '%s.{}.jpg' % i_class\n",
    "    fnames = [fname_pattern.format(i) for i in range(0, 3000)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(sour_dir, step_set[0], fname)\n",
    "        det = os.path.join(dest_dir, step_set[0], class_set[i_idx], fname)\n",
    "        shutil.copyfile(src, det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move 500 cat/dog images to valid_dir. range(1000, 1500)\n",
    "# Move 500 cat/dog images to test_dir. range(1500, 2000)\n",
    "for i_step in step_set[1:3]:\n",
    "    for i_idx, i_class in enumerate(class_set):\n",
    "        fname_pattern = '%s.{}.jpg' % class_fname_set[i_idx]\n",
    "        if i_step == 'valid':\n",
    "            fnames = [fname_pattern.format(i) for i in range(1000, 1500)]\n",
    "        else:\n",
    "            fnames = [fname_pattern.format(i) for i in range(1500, 2000)]\n",
    "        # print(fnames)\n",
    "        for fname in fnames:\n",
    "            src = os.path.join(dest_dir, step_set[0], i_class, fname)\n",
    "            det = os.path.join(dest_dir, i_step, i_class, fname)\n",
    "            shutil.move(src, det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images: 2000\n",
      "total training dog images: 2000\n",
      "total validation cat images: 500\n",
      "total validation dog images: 500\n",
      "total test cat images: 500\n",
      "total test dog images: 500\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks\n",
    "print('total training cat images:', len(os.listdir(os.path.join(dest_dir, step_set[0], class_set[0]))))\n",
    "print('total training dog images:', len(os.listdir(os.path.join(dest_dir, step_set[0], class_set[1]))))\n",
    "print('total validation cat images:', len(os.listdir(os.path.join(dest_dir, step_set[1], class_set[0]))))\n",
    "print('total validation dog images:', len(os.listdir(os.path.join(dest_dir, step_set[1], class_set[1]))))\n",
    "print('total test cat images:', len(os.listdir(os.path.join(dest_dir, step_set[2], class_set[0]))))\n",
    "print('total test dog images:', len(os.listdir(os.path.join(dest_dir, step_set[2], class_set[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 圖片預處理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ryanyao/docker_mount/data/dogs_vs_cats_dir/train\n",
      "/home/ryanyao/docker_mount/data/dogs_vs_cats_dir/valid\n",
      "/home/ryanyao/docker_mount/data/dogs_vs_cats_dir/test\n"
     ]
    }
   ],
   "source": [
    "img_base = '/home/ryanyao/docker_mount/data/dogs_vs_cats_dir/'\n",
    "train_path = os.path.join(img_base,'train')\n",
    "valid_path = os.path.join(img_base,'valid')\n",
    "test_path = os.path.join(img_base,'test')\n",
    "print(train_path, valid_path, test_path, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['dogs', 'cats'], batch_size=batch_size)\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['dogs', 'cats'], batch_size=batch_size)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['dogs', 'cats'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# 檢視 image input size\n",
    "print(train_batches.image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "* 下載 Keras NobileNet model 進行 transfer learning，並計算其 test dataset 的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanyao/anaconda3/lib/python3.7/site-packages/keras_applications/mobilenet.py:208: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "#imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "base_model = MobileNet(weights='imagenet', include_top=False) \n",
    "\n",
    "x = base_model.output\n",
    "# we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(1024, activation='relu')(x) \n",
    "x = Dense(512, activation='relu')(x)\n",
    "preds = Dense(2, activation='softmax')(x) # final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the model architecture\n",
    "# for i,layer in enumerate(model.layers):\n",
    "#     print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will only train the last few dense layers.\n",
    "# if we want to set the first 20 layers of the network to be non-trainable\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,754,690\n",
      "Trainable params: 3,718,786\n",
      "Non-trainable params: 35,904\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 輸出整個網路結構\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      " - 21s - loss: 0.3044 - acc: 0.8888 - val_loss: 0.9725 - val_acc: 0.5060\n",
      "Epoch 2/10\n",
      " - 17s - loss: 0.1974 - acc: 0.9295 - val_loss: 0.6346 - val_acc: 0.6420\n",
      "Epoch 3/10\n",
      " - 17s - loss: 0.1421 - acc: 0.9515 - val_loss: 0.7035 - val_acc: 0.5660\n",
      "Epoch 4/10\n",
      " - 17s - loss: 0.1006 - acc: 0.9647 - val_loss: 0.6997 - val_acc: 0.5430\n",
      "Epoch 5/10\n",
      " - 17s - loss: 0.1116 - acc: 0.9607 - val_loss: 2.4261 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      " - 17s - loss: 0.0846 - acc: 0.9700 - val_loss: 1.4644 - val_acc: 0.5010\n",
      "Epoch 7/10\n",
      " - 17s - loss: 0.0578 - acc: 0.9778 - val_loss: 0.8009 - val_acc: 0.5990\n",
      "Epoch 8/10\n",
      " - 17s - loss: 0.0687 - acc: 0.9755 - val_loss: 0.8377 - val_acc: 0.4670\n",
      "Epoch 9/10\n",
      " - 17s - loss: 0.0486 - acc: 0.9840 - val_loss: 2.0646 - val_acc: 0.5530\n",
      "Epoch 10/10\n",
      " - 17s - loss: 0.0420 - acc: 0.9860 - val_loss: 0.6224 - val_acc: 0.6440\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "step_size_train = train_batches.n // train_batches.batch_size\n",
    "step_size_valid = valid_batches.n // valid_batches.batch_size\n",
    "history = model.fit_generator(generator=train_batches, \n",
    "                    steps_per_epoch=step_size_train, \n",
    "                    validation_data=valid_batches,\n",
    "                    validation_steps=step_size_valid,\n",
    "                    epochs=10,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6372752715349197, 0.631]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_test = test_batches.n // test_batches.batch_size\n",
    "model.evaluate_generator(generator=test_batches, steps=step_size_test, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
